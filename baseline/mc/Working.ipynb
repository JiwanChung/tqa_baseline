{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from tensorboard import Logger\n",
    "from utils.ReCuda import ReCuda\n",
    "\n",
    "from readData import get_data\n",
    "from model import TextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "def setup():\n",
    "    if not os.path.isdir('logs'):\n",
    "        os.mkdir('logs')\n",
    "    logger = Logger('./logs')\n",
    "\n",
    "    args = type('test', (), {})()\n",
    "    args.train=False\n",
    "    args.test = False\n",
    "    args.ckpt = None\n",
    "    \n",
    "    args.source_dir = '/home/jiwan/tqa/prepro/data'\n",
    "    args.ckpt_dir = './ckpt'\n",
    "    args.emb_dim = 300\n",
    "    args.repeat = False\n",
    "    args.learning_rate = 0.001\n",
    "    args.if_pair = False\n",
    "    args.log_epoch = 4\n",
    "    args.bi_gru = True\n",
    "    args.batch_size = 36\n",
    "    args.verbose = False\n",
    "    args.end_epoch = 100\n",
    "    args.single_topic = False\n",
    "\n",
    "    args.test_iter = 'val'\n",
    "\n",
    "    args.cuda = True\n",
    "    if not torch.cuda.is_available():\n",
    "        args.cuda = False\n",
    "\n",
    "    config = args\n",
    "    config.recuda = ReCuda(config)\n",
    "    config.resume = False\n",
    "    if config.ckpt is not None:\n",
    "        config.resume = True\n",
    "    config.single_topic_ckpt = ''\n",
    "    if not config.single_topic:\n",
    "        config.single_topic_ckpt = '_all'\n",
    "\n",
    "    config.logger = logger\n",
    "\n",
    "    config.recuda.torch.manual_seed(1)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "\n",
    "##\n",
    "# get net\n",
    "def get_net(config, vocab):\n",
    "    if config.resume:\n",
    "        print('RESUME {}th epoch'.format(config.ckpt))\n",
    "        assert os.path.isdir('ckpt'), 'Error: no dir'\n",
    "        ckpt = torch.load(os.path.join(config.ckpt_dir, 'ckpt{}_{}.t7'.format(config.single_topic_ckpt, config.ckpt)))\n",
    "        net = TextModel(vocab, config, 100)\n",
    "        net.load_state_dict(ckpt['params'])\n",
    "        best_acc = ckpt['acc']\n",
    "        start_epoch = ckpt['epoch']\n",
    "    else:\n",
    "        net = TextModel(vocab, config, 100)\n",
    "        best_acc = 0\n",
    "        start_epoch = 0\n",
    "    net = config.recuda.var(net)\n",
    "    print('PARAMS: ', net.parameters)\n",
    "    return net, best_acc, start_epoch\n",
    "\n",
    "\n",
    "##\n",
    "def run_net(net, config, data):\n",
    "    answers_size = len(data.answers)\n",
    "    answers = torch.stack(data.answers, dim=2)\n",
    "        \n",
    "    if config.single_topic:\n",
    "        topics = data.topic.data\n",
    "    else:\n",
    "        topics = torch.stack(data.topic, dim=2)\n",
    "\n",
    "    target = Variable(data.correct_answer.data, requires_grad=False)\n",
    "    target = config.recuda.var(target)\n",
    "    print('t:', topics.size(), type(topics))\n",
    "    # run\n",
    "    return net.forward(topics, data.question, answers, answers_size)\n",
    "\n",
    "##\n",
    "def train_epoch(net, config, data, train_iter, epoch):\n",
    "\n",
    "    # train\n",
    "    train_loss = 0\n",
    "    for batch_index, data in tqdm(enumerate(train_iter)):\n",
    "        net.zero_grad()\n",
    "        \n",
    "        y = run_net(net, config, data)\n",
    "        if config.verbose:\n",
    "            print('y:', y.data)\n",
    "            print('t:', target.data)\n",
    "        loss = config.loss_fn(y, target)\n",
    "        # count loss\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        config.optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        loss_per = train_loss/(batch_index+1)\n",
    "        print(\"Training {} epoch, loss: {}\".format(epoch, loss_per))\n",
    "        config.logger.scalar_summary('tr_loss', loss_per, epoch+1)\n",
    "\n",
    "##\n",
    "def validate_epoch(net, config, data, val_iter, epoch):\n",
    "    # validate from time to time\n",
    "\n",
    "    print(\"begin validation\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for index_v, data in tqdm(enumerate(val_iter)):\n",
    "        y = run_net(net, config, data)\n",
    "        \n",
    "        value, pred = torch.max(y, 1)\n",
    "        check = torch.eq(data.correct_answer.data, pred.data)\n",
    "        if config.verbose:\n",
    "            print(torch.sum(check), check.size())\n",
    "        correct += torch.sum(check)\n",
    "        total += (check.size()[0])\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    print(\"Val {} epoch, acc: {}\".format(epoch, acc))\n",
    "\n",
    "    config.logger.scalar_summary('val_acc', acc, (epoch + 1))\n",
    "\n",
    "    return acc\n",
    "\n",
    "##\n",
    "def save_net(net, config, epoch, acc):\n",
    "    print('saving')\n",
    "    state = {\n",
    "        'params': net.state_dict(),\n",
    "        'acc': acc,\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    if not os.path.isdir('ckpt'):\n",
    "        os.mkdir('ckpt')\n",
    "    torch.save(state, os.path.join(config.ckpt_dir, 'ckpt{}_{}.t7'.format(config.single_topic_ckpt,epoch)))\n",
    "\n",
    "\n",
    "##\n",
    "def train_all(net, data, iters, config):\n",
    "    config.loss_fn = nn.CrossEntropyLoss()\n",
    "    config.optimizer = torch.optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    for epoch in range(config.start_epoch, config.end_epoch):\n",
    "        print(\"{} epoch\".format(epoch))\n",
    "        train_epoch(net, config, data, iters['train'], epoch)\n",
    "        acc = validate_epoch(net, config, data, iters['val'], epoch)\n",
    "\n",
    "        save_net(net, config, epoch, acc)\n",
    "##\n",
    "\n",
    "\n",
    "def test_epoch(net, config, data, test_iter):\n",
    "    test_net = Counter()\n",
    "    net_dict = {}\n",
    "\n",
    "    print(\"begin testing\")\n",
    "    for index_t, data in tqdm(enumerate(test_iter)):\n",
    "        y = run_net(net, config, data)\n",
    "        \n",
    "        value, pred = torch.max(y, 1)\n",
    "        check = torch.eq(data.correct_answer.data, pred.data)\n",
    "        for i in range(len(check)):\n",
    "            test_net[data.id[i]] += int(check[i])\n",
    "            net_dict[data.id[i]] = [pred.data[i], data.correct_answer.data[i]]\n",
    "\n",
    "    return test_net, net_dict\n",
    "\n",
    "\n",
    "def test_all(net, data, test_iter, config):\n",
    "    test_counter, test_dict = test_epoch(net, config, data, test_iter)\n",
    "\n",
    "    with open(os.path.join(config.source_dir, 'correct_counter_{}.pickle'.format(config.test_iter)), 'wb') as outfile:\n",
    "        pickle.dump(test_counter, outfile)\n",
    "\n",
    "    with open(os.path.join(config.source_dir, 'correct_dict_{}.pickle'.format(config.test_iter)), 'wb') as outfile:\n",
    "        pickle.dump(test_dict, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data_train_full.tsv, data_test_full.tsv, data_val_full.tsv\n"
     ]
    }
   ],
   "source": [
    "data, iters, vocab = get_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "('PARAMS: ', <bound method TextModel.parameters of TextModel(\n",
      "  (embed): Embedding(27226, 300)\n",
      "  (embed_context): GRU(300, 100, bidirectional=True)\n",
      "  (embed_question): GRU(300, 100, bidirectional=True)\n",
      "  (embed_answer): GRU(300, 100, bidirectional=True)\n",
      ")>)\n"
     ]
    }
   ],
   "source": [
    "print('loading model')\n",
    "net, best_acc, config.start_epoch = get_net(config, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextModelMain(\n",
       "  (embed): Embedding(27226, 300)\n",
       "  (embed_context): GRU(300, 100, bidirectional=True)\n",
       "  (embed_question): GRU(300, 100, bidirectional=True)\n",
       "  (embed_answer): GRU(300, 100, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class TextModelMain(nn.Module):\n",
    "    def __init__(self, vocab, config, embed_size):\n",
    "        super(TextModelMain, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.config = config\n",
    "\n",
    "        self.embed = nn.Embedding(len(vocab), config.emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab.vectors)\n",
    "\n",
    "        self.bi = 2 if config.bi_gru else 1\n",
    "\n",
    "        self.embed_context = nn.GRU(config.emb_dim, embed_size, bidirectional=config.bi_gru)\n",
    "        self.embed_question = nn.GRU(config.emb_dim, embed_size, bidirectional=config.bi_gru)\n",
    "        self.embed_answer = nn.GRU(config.emb_dim, embed_size, bidirectional=config.bi_gru)\n",
    "\n",
    "    def forward(self, context, question, answers, answers_size):\n",
    "\n",
    "        if not self.config.single_topic:\n",
    "            context_shape = list(context.data.size())\n",
    "            context_shape.append(self.config.emb_dim)\n",
    "            context = context.view(-1, context.size()[2])\n",
    "        \n",
    "        context = self.embed(context)\n",
    "        question = self.embed(question)\n",
    "\n",
    "        if not self.config.single_topic:\n",
    "            context = context.view(*context_shape)\n",
    "            context = torch.sum(context, 1) # sum along num of topics\n",
    "\n",
    "        M, hm = self.embed_context(context) # P x embed_size\n",
    "        U, hu = self.embed_question(question) # Q X embed_size\n",
    "\n",
    "        M = M.permute(1,0,2)\n",
    "        U = U.permute(1,2,0)\n",
    "        S = torch.matmul(M, U)\n",
    "        S, S_index = torch.max(S, dim=2)\n",
    "        a = F.softmax(S).unsqueeze(0).permute(1,2,0)\n",
    "        a = a.expand(M.data.size())\n",
    "        m = torch.mul(a, M)\n",
    "        m = torch.sum(m, 1).unsqueeze(0)\n",
    "\n",
    "        origin_size = answers.data.size()\n",
    "        answers = answers.view(-1, answers.size()[2])\n",
    "        if self.config.verbose:\n",
    "            if len(answers.data.size()) < 3:\n",
    "                print(answers.data)\n",
    "        answers = self.embed(answers)\n",
    "        C, hc = self.embed_answer(answers) # A X embed_size\n",
    "        C = C.unsqueeze(0).view(origin_size[0], origin_size[1], origin_size[2], self.bi*self.embed_size)\n",
    "        c = torch.sum(C, dim=0)\n",
    "        r = torch.matmul(m.permute(1,0,2), c.permute(1,2,0)).squeeze()\n",
    "\n",
    "        return r\n",
    "\n",
    "net = TextModelMain(vocab, config, 100)\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start Testing\n",
      "begin testing\n",
      "('t:', torch.Size([105, 16, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jiwan/p2/lib/python2.7/site-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "3it [00:01,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([169, 16, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([169, 14, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([248, 8, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([248, 18, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([254, 18, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([254, 12, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([163, 13, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([145, 9, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([145, 21, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([171, 21, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([229, 19, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([451, 9, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:01,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([451, 8, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([282, 14, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([249, 18, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:02,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([515, 18, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([515, 8, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([338, 5, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:02,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([209, 4, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([283, 4, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([234, 5, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([198, 5, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([239, 11, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:02, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([292, 3, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([226, 9, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([284, 6, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([185, 7, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "30it [00:02, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([256, 6, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([276, 8, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([202, 7, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([181, 10, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:02, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([192, 10, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([286, 8, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([255, 8, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([264, 10, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:03, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([264, 19, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([199, 19, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([199, 13, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([194, 15, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:03, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([158, 15, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([225, 14, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([459, 14, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "45it [00:03, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([399, 6, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([498, 6, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([303, 6, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([327, 3, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:03, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([410, 5, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([492, 4, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([433, 4, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([234, 5, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:04, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([234, 5, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([207, 12, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([295, 12, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([301, 11, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [00:04, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([301, 5, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([252, 5, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([284, 7, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([495, 10, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [00:04, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([495, 10, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([248, 8, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([218, 13, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:04, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([251, 13, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([278, 4, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([229, 4, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([218, 4, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([342, 5, 36]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [00:05, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([441, 10, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([348, 4, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([291, 5, 36]), <class 'torch.autograd.variable.Variable'>)\n",
      "('t:', torch.Size([291, 3, 4]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if config.train:\n",
    "    print(\"Let\\'s start Training\")\n",
    "    train_all(net, data, iters, config)\n",
    "else:\n",
    "    print(\"Let\\'s start Testing\")\n",
    "    test_all(net, data, iters[config.test_iter], config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
