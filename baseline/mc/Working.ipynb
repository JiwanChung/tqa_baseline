{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from tensorboard import Logger\n",
    "from utils.ReCuda import ReCuda\n",
    "\n",
    "from readData import get_data\n",
    "from model import TextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "def setup():\n",
    "    if not os.path.isdir('logs'):\n",
    "        os.mkdir('logs')\n",
    "    logger = Logger('./logs')\n",
    "\n",
    "    args = type('test', (), {})()\n",
    "    args.train=False\n",
    "    args.test = False\n",
    "    args.ckpt = None\n",
    "    \n",
    "    args.source_dir = '/home/jiwan/tqa/prepro/data'\n",
    "    args.ckpt_dir = './ckpt'\n",
    "    args.emb_dim = 300\n",
    "    args.repeat = False\n",
    "    args.learning_rate = 0.001\n",
    "    args.if_pair = False\n",
    "    args.log_epoch = 4\n",
    "    args.bi_gru = True\n",
    "    args.batch_size = 36\n",
    "    args.verbose = False\n",
    "    args.end_epoch = 100\n",
    "    args.single_topic = False\n",
    "\n",
    "    args.test_iter = 'val'\n",
    "    \n",
    "    args.sample = True\n",
    "\n",
    "    args.cuda = True\n",
    "    if not torch.cuda.is_available():\n",
    "        args.cuda = False\n",
    "\n",
    "    config = args\n",
    "    config.recuda = ReCuda(config)\n",
    "    config.resume = False\n",
    "    if config.ckpt is not None:\n",
    "        config.resume = True\n",
    "    config.single_topic_ckpt = ''\n",
    "    if not config.single_topic:\n",
    "        config.single_topic_ckpt = '_all'\n",
    "\n",
    "    config.logger = logger\n",
    "\n",
    "    config.recuda.torch.manual_seed(1)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "\n",
    "##\n",
    "# get net\n",
    "def get_net(config, vocab):\n",
    "    config.embed_size = 100\n",
    "    if config.resume:\n",
    "        print('RESUME {}th epoch'.format(config.ckpt))\n",
    "        assert os.path.isdir('ckpt'), 'Error: no dir'\n",
    "        ckpt = torch.load(os.path.join(config.ckpt_dir, 'ckpt{}_{}.t7'.format(config.single_topic_ckpt, config.ckpt)))\n",
    "        net = TextModel(vocab, config)\n",
    "        net.load_state_dict(ckpt['params'])\n",
    "        best_acc = ckpt['acc']\n",
    "        start_epoch = ckpt['epoch']\n",
    "    else:\n",
    "        net = TextModel(vocab, config)\n",
    "        best_acc = 0\n",
    "        start_epoch = 0\n",
    "    net = config.recuda.var(net)\n",
    "    print('PARAMS: ', net.parameters)\n",
    "    return net, best_acc, start_epoch\n",
    "\n",
    "\n",
    "##\n",
    "def run_net(net, config, data):\n",
    "    answers_size = len(data.answers)\n",
    "    answers = torch.stack(data.answers, dim=2)\n",
    "        \n",
    "    if config.single_topic:\n",
    "        topics = data.topic.data\n",
    "    else:\n",
    "        topics = torch.stack(data.topic, dim=2)\n",
    "\n",
    "    target = Variable(data.correct_answer.data, requires_grad=False)\n",
    "    target = config.recuda.var(target)\n",
    "    print('t:', topics.size(), type(topics))\n",
    "    # run\n",
    "    return net.forward(topics, data.question, answers, answers_size)\n",
    "\n",
    "##\n",
    "def train_epoch(net, config, data, train_iter, epoch):\n",
    "\n",
    "    # train\n",
    "    train_loss = 0\n",
    "    for batch_index, data in tqdm(enumerate(train_iter)):\n",
    "        net.zero_grad()\n",
    "        \n",
    "        y = run_net(net, config, data)\n",
    "        if config.verbose:\n",
    "            print('y:', y.data)\n",
    "            print('t:', target.data)\n",
    "        loss = config.loss_fn(y, target)\n",
    "        # count loss\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        config.optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        loss_per = train_loss/(batch_index+1)\n",
    "        print(\"Training {} epoch, loss: {}\".format(epoch, loss_per))\n",
    "        config.logger.scalar_summary('tr_loss', loss_per, epoch+1)\n",
    "\n",
    "##\n",
    "def validate_epoch(net, config, data, val_iter, epoch):\n",
    "    # validate from time to time\n",
    "\n",
    "    print(\"begin validation\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for index_v, data in tqdm(enumerate(val_iter)):\n",
    "        y = run_net(net, config, data)\n",
    "        \n",
    "        value, pred = torch.max(y, 1)\n",
    "        check = torch.eq(data.correct_answer.data, pred.data)\n",
    "        if config.verbose:\n",
    "            print(torch.sum(check), check.size())\n",
    "        correct += torch.sum(check)\n",
    "        total += (check.size()[0])\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    print(\"Val {} epoch, acc: {}\".format(epoch, acc))\n",
    "\n",
    "    config.logger.scalar_summary('val_acc', acc, (epoch + 1))\n",
    "\n",
    "    return acc\n",
    "\n",
    "##\n",
    "def save_net(net, config, epoch, acc):\n",
    "    print('saving')\n",
    "    state = {\n",
    "        'params': net.state_dict(),\n",
    "        'acc': acc,\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    if not os.path.isdir('ckpt'):\n",
    "        os.mkdir('ckpt')\n",
    "    torch.save(state, os.path.join(config.ckpt_dir, 'ckpt{}_{}.t7'.format(config.single_topic_ckpt,epoch)))\n",
    "\n",
    "\n",
    "##\n",
    "def train_all(net, data, iters, config):\n",
    "    config.loss_fn = nn.CrossEntropyLoss()\n",
    "    config.optimizer = torch.optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    for epoch in range(config.start_epoch, config.end_epoch):\n",
    "        print(\"{} epoch\".format(epoch))\n",
    "        train_epoch(net, config, data, iters['train'], epoch)\n",
    "        acc = validate_epoch(net, config, data, iters['val'], epoch)\n",
    "\n",
    "        save_net(net, config, epoch, acc)\n",
    "##\n",
    "\n",
    "\n",
    "def test_epoch(net, config, data, test_iter):\n",
    "    test_net = Counter()\n",
    "    net_dict = {}\n",
    "\n",
    "    print(\"begin testing\")\n",
    "    for index_t, data in tqdm(enumerate(test_iter)):\n",
    "        y = run_net(net, config, data)\n",
    "        \n",
    "        value, pred = torch.max(y, 1)\n",
    "        check = torch.eq(data.correct_answer.data, pred.data)\n",
    "        for i in range(len(check)):\n",
    "            test_net[data.id[i]] += int(check[i])\n",
    "            net_dict[data.id[i]] = [pred.data[i], data.correct_answer.data[i]]\n",
    "\n",
    "    return test_net, net_dict\n",
    "\n",
    "\n",
    "def test_all(net, data, test_iter, config):\n",
    "    test_counter, test_dict = test_epoch(net, config, data, test_iter)\n",
    "\n",
    "    with open(os.path.join(config.source_dir, 'correct_counter_{}.pickle'.format(config.test_iter)), 'wb') as outfile:\n",
    "        pickle.dump(test_counter, outfile)\n",
    "\n",
    "    with open(os.path.join(config.source_dir, 'correct_dict_{}.pickle'.format(config.test_iter)), 'wb') as outfile:\n",
    "        pickle.dump(test_dict, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data_train_full_sample.tsv, data_test_full_sample.tsv, data_val_full_sample.tsv\n"
     ]
    }
   ],
   "source": [
    "data, iters, vocab = get_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "('PARAMS: ', <bound method TextModel.parameters of TextModel(\n",
      "  (embed): Embedding(453, 300)\n",
      "  (embed_context): GRU(300, 100, bidirectional=True)\n",
      "  (embed_question): GRU(300, 100, bidirectional=True)\n",
      "  (embed_answer): GRU(300, 100, bidirectional=True)\n",
      ")>)\n"
     ]
    }
   ],
   "source": [
    "print('loading model')\n",
    "net, best_acc, config.start_epoch = get_net(config, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextModelMain(\n",
       "  (embed): Embedding(453, 300)\n",
       "  (embed_context): GRU(300, 100, bidirectional=True)\n",
       "  (embed_question): GRU(300, 100, bidirectional=True)\n",
       "  (embed_answer): GRU(300, 100, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class TextModelMain(nn.Module):\n",
    "    def __init__(self, vocab, config, embed_size):\n",
    "        super(TextModelMain, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.config = config\n",
    "\n",
    "        self.embed = nn.Embedding(len(vocab), config.emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab.vectors)\n",
    "\n",
    "        self.bi = 2 if config.bi_gru else 1\n",
    "\n",
    "        self.embed_context = nn.GRU(config.emb_dim, embed_size, bidirectional=config.bi_gru)\n",
    "        self.embed_question = nn.GRU(config.emb_dim, embed_size, bidirectional=config.bi_gru)\n",
    "        self.embed_answer = nn.GRU(config.emb_dim, embed_size, bidirectional=config.bi_gru)\n",
    "\n",
    "    def forward(self, context, question, answers, answers_size):\n",
    "\n",
    "        if not self.config.single_topic:\n",
    "            context_shape = list(context.data.size())\n",
    "            context_shape.append(self.config.emb_dim)\n",
    "            context = context.view(-1, context.size()[2])\n",
    "        \n",
    "        context = self.embed(context)\n",
    "        question = self.embed(question)\n",
    "\n",
    "        if not self.config.single_topic:\n",
    "            context = context.view(*context_shape)\n",
    "            context = torch.sum(context, 1) # sum along num of topics\n",
    "\n",
    "        M, hm = self.embed_context(context) # P x embed_size\n",
    "        U, hu = self.embed_question(question) # Q X embed_size\n",
    "\n",
    "        M = M.permute(1,0,2)\n",
    "        U = U.permute(1,2,0)\n",
    "        S = torch.matmul(M, U)\n",
    "        S, S_index = torch.max(S, dim=2)\n",
    "        a = F.softmax(S).unsqueeze(0).permute(1,2,0)\n",
    "        a = a.expand(M.data.size())\n",
    "        m = torch.mul(a, M)\n",
    "        m = torch.sum(m, 1).unsqueeze(0)\n",
    "\n",
    "        origin_size = answers.data.size()\n",
    "        answers = answers.view(-1, answers.size()[2])\n",
    "        if self.config.verbose:\n",
    "            if len(answers.data.size()) < 3:\n",
    "                print(answers.data)\n",
    "        answers = self.embed(answers)\n",
    "        C, hc = self.embed_answer(answers) # A X embed_size\n",
    "        C = C.unsqueeze(0).view(origin_size[0], origin_size[1], origin_size[2], self.bi*self.embed_size)\n",
    "        c = torch.sum(C, dim=0)\n",
    "        r = torch.matmul(m.permute(1,0,2), c.permute(1,2,0)).squeeze()\n",
    "\n",
    "        return r\n",
    "\n",
    "net = TextModelMain(vocab, config, 100)\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start Testing\n",
      "begin testing\n",
      "('t:', torch.Size([105, 6, 9]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jiwan/p2/lib/python2.7/site-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "1it [00:00,  4.27it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if config.train:\n",
    "    print(\"Let\\'s start Training\")\n",
    "    train_all(net, data, iters, config)\n",
    "else:\n",
    "    print(\"Let\\'s start Testing\")\n",
    "    test_all(net, data, iters[config.test_iter], config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = next(iter(iters['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t:', torch.Size([226, 5, 9]), <class 'torch.autograd.variable.Variable'>)\n"
     ]
    }
   ],
   "source": [
    "answers_size = len(data1.answers)\n",
    "answers = torch.stack(data1.answers, dim=2)\n",
    "        \n",
    "if config.single_topic:\n",
    "    topics = data1.topic.data\n",
    "else:\n",
    "    topics = torch.stack(data1.topic, dim=2)\n",
    "target = Variable(data1.correct_answer.data, requires_grad=False)\n",
    "target = config.recuda.var(target)\n",
    "print('t:', topics.size(), type(topics))\n",
    "# run\n",
    "context = topics.cpu()\n",
    "question = data1.question.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab), config.emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab.vectors)\n",
    "        self.embed_context = nn.GRU(config.emb_dim, config.embed_size, bidirectional=config.bi_gru)\n",
    "        self.embed_question = nn.GRU(config.emb_dim, config.embed_size, bidirectional=config.bi_gru)\n",
    "        self.embed_answer = nn.GRU(config.emb_dim, config.embed_size, bidirectional=config.bi_gru)\n",
    "        self.normalize_row = nn.Softmax(dim=2) # normalize along words of topic\n",
    "\n",
    "        \n",
    "    def forward(self, CO, Q, A):\n",
    "\n",
    "        context_shape = list(CO.data.size())\n",
    "        batch_size = context_shape[2]\n",
    "        context_shape.append((config.embed_size* config.bi))\n",
    "        CO = CO.view(-1, CO.size()[2])\n",
    "\n",
    "        answer_shape = list(A.data.size())\n",
    "        answer_shape.append((config.embed_size* config.bi))\n",
    "        A = A.view(-1, A.size()[2])\n",
    "\n",
    "        CO = self.embed(CO)\n",
    "        Q = self.embed(Q)\n",
    "        A = self.embed(A)\n",
    "\n",
    "        CO, hc = self.embed_context(CO) # P x embed_size\n",
    "        CO = CO.view(*context_shape)\n",
    "        Q, hq = self.embed_question(Q) # Q X embed_size\n",
    "        A, ha = self.embed_answer(A)\n",
    "        A = A.view(*answer_shape) # A X embed_size\n",
    "\n",
    "        CO = CO.permute(1, 2, 0, 3) # topic_num, batch_size, words_topic, embed_size\n",
    "        Q = Q.permute(1, 2, 0) # batch_size, embed_size, words_question\n",
    "        A = A.permute(2, 3, 0, 1) # batch_size, embed_size, words_answer, answer_num\n",
    "\n",
    "        C = CO # store data\n",
    "\n",
    "        # <attention>\n",
    "        S = torch.matmul(C, Q) # topic_num, batch_size, words_topic, words_question\n",
    "        S = self.normalize_row(S) # attention practice based on QAnet (Google)\n",
    "        Att = torch.matmul(S, Q.permute(0, 2, 1)) # Q: batch_size, words_question, embed_size\n",
    "        # Att: topic_num, batch_size, words_topic, embed_size\n",
    "        C = F.normalize(C, dim=2) # normalize along words_topic, removing bias in total num of words\n",
    "        C = torch.mul(Att, C) # apply attention\n",
    "        C = torch.sum(torch.sum(C, 3), 2) # reduce dimension\n",
    "        # </attention>\n",
    "\n",
    "        maxval, argmax = torch.max(C, 0) # pick top 1 topic\n",
    "        c = CO[argmax, torch.arange(0, batch_size).long(), :] # reduce based on top 1 indices\n",
    "        c = c.permute(0, 2, 1) # batch_size, embed_size, words_topic \n",
    "        \n",
    "        return c, Q, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(MemoryAttention, self).__init__()\n",
    "        \n",
    "        self.dim_words = config.dim_words\n",
    "        self.keys = config.keys\n",
    "        \n",
    "        # linear mapping\n",
    "        self.linear_map = {}\n",
    "        for key in self.keys:\n",
    "            self.linear_map[key] = nn.Linear(config.q_size * config.h_size, config.sizes[key])\n",
    "        \n",
    "    def forward(self, MO, qa, h):\n",
    "        \n",
    "        M = MO\n",
    "        keys = self.keys\n",
    "        \n",
    "        size = {}\n",
    "        for key in keys:\n",
    "            size[key] = list(M[key].size())\n",
    "\n",
    "        S = torch.matmul(qa.unsqueeze(3), h.unsqueeze(2))\n",
    "        s_size = S.size()\n",
    "        S = S.view(s_size[0], s_size[1], -1)\n",
    "        # attention\n",
    "        a = {}\n",
    "        for key in keys:\n",
    "            a[key] = torch.mul(M[key], self.linear_map[key](S))\n",
    "            a[key] = F.softmax(a[key], dim=self.dim_words)\n",
    "        # attention score\n",
    "        scores = {}\n",
    "        for key in keys:\n",
    "            scores[key] = torch.norm(a[key], dim=self.dim_words)\n",
    "            scores[key] = scores[key].unsqueeze(2)\n",
    "\n",
    "        tuple_a = ()\n",
    "        index_a = {}\n",
    "        for i, key in enumerate(keys):\n",
    "            tuple_a += (scores[key], )\n",
    "            index_a[key] = i\n",
    "\n",
    "        # score to softmax index of attending memory type\n",
    "        score = torch.cat(tuple_a, dim=2)\n",
    "        score = F.softmax(score, dim=self.dim_words)\n",
    "\n",
    "        for key in keys:\n",
    "            coeff = torch.index_select(score, self.dim_words, Variable(config.recuda.torch.LongTensor([index_a[key]])))\n",
    "            a[key] = torch.matmul(a[key].unsqueeze(3), coeff.unsqueeze(2))\n",
    "            a[key] = a[key].squeeze()\n",
    "\n",
    "        m = {key : torch.mul(M[key], a[key]) for key in keys}\n",
    "\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModule(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(SimpleModule, self).__init__()\n",
    "        \n",
    "        self.memory_attention = MemoryAttention(config)\n",
    "        self.reasoning = Reasoning(config)\n",
    "        self.question_attend = QuestionAttend(config)\n",
    "        self.forget_gate = ForgetGate(config)\n",
    "        self.confidence = Confidence(config)\n",
    "        self.output = Output(config)\n",
    "        \n",
    "    def forward(self, M, qa, h):\n",
    "        '''\n",
    "        M = [c, A], \n",
    "        c: batch_size, embed_size, words_topic\n",
    "        A: batch_size, embed_size, words_answer, answer_num\n",
    "        qa: batch_size, embed_size, words_question\n",
    "        h: batch_size, h_size\n",
    "        '''\n",
    "        m = self.memory_attention(M, qa, h)\n",
    "        x = self.reasoning(h, m)\n",
    "        \n",
    "        qa = self.question_attend(qa, x)\n",
    "        \n",
    "        h = self.forget_gate(h, x)\n",
    "        conf = self.confidence(h)\n",
    "        o = self.output(h)\n",
    "        \n",
    "        return qa, h, o, conf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POCController(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        # hyperNetwork\n",
    "        super(POCController, self).__init__()\n",
    "        \n",
    "        self.k = config.k # MAX num of steps\n",
    "        self.conf_theshold = config.conf\n",
    "        \n",
    "        self.batch_size = config.batch_size\n",
    "        self.h_size = config.h_size\n",
    "        self.emb = config.embed_size * config.bi\n",
    "        \n",
    "        self.init_h = lambda size_list: Variable(torch.zeros(*size_list))\n",
    "\n",
    "        self.module = SimpleModule(config)\n",
    "    \n",
    "    def forward(self, M, qa):\n",
    "        h = self.init_h([self.batch_size, self.emb, self.h_size])\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            # run module\n",
    "            qa, h, o, conf = self.module(M, qa, h)\n",
    "            #if conf > self.conf_theshold:\n",
    "                #break\n",
    "        \n",
    "        return o, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        # hyperNetwork\n",
    "        super(Controller, self).__init__()\n",
    "        \n",
    "        self.k = config.k # MAX num of steps\n",
    "        self.conf_theshold = config.conf\n",
    "        \n",
    "        self.batch_size = config.batch_size\n",
    "        self.h_size = config.h_size\n",
    "        self.emb = config.embed_size * config.bi\n",
    "\n",
    "        self.init_h = lambda size_list: Variable(torch.zeros(*size_list))\n",
    "\n",
    "        self.module = SimpleModule(config)\n",
    "    \n",
    "    def forward(self, M, qa):\n",
    "        h = self.init_h([self.batch_size, self.emb, self.h_size])\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            # generate weight\n",
    "        \n",
    "            # inject weight\n",
    "        \n",
    "            # run module\n",
    "            qa, h, o, conf = self.module(M, qa, h)\n",
    "            if conf > self.conf_theshold:\n",
    "                break\n",
    "        \n",
    "        return o, conf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        # hyperNetwork\n",
    "        super(ModuleNet, self).__init__()\n",
    "        \n",
    "        self.h_size = config.h_size\n",
    "        self.dim_words = config.dim_words\n",
    "        \n",
    "        self.encoder = Encoder(config)\n",
    "        self.controller = Controller(config) if config.hyper else POCController(config)\n",
    "        self.init_h = lambda size_list: Variable(torch.zeros(*size_list))\n",
    "        self.decoder = Decoder(config)\n",
    "        \n",
    "    def forward(self, CO, Q, A):\n",
    "        batch_size = A.size()[0]\n",
    "        \n",
    "        # encoding layer\n",
    "        c, q, A = self.encoder.forward(CO, Q, A)\n",
    "        M = {'c': c}\n",
    "        \n",
    "        # reasoning layer\n",
    "        MA = torch.sum(A, dim=(self.dim_words + 1)).squeeze()\n",
    "        M['A'] =  MA # A to memory\n",
    "        o, conf = self.controller(M, q)\n",
    "        \n",
    "        # decoder layer\n",
    "        p = self.decoder(o, A)\n",
    "        p = conf * p\n",
    "        \n",
    "        return p     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual block from resnet\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reasoning(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Reasoning, self).__init__()\n",
    "        \n",
    "        self.dim_words = config.dim_words\n",
    "        self.keys = config.keys\n",
    "        self.sizes = config.sizes\n",
    "        planes = config.reasoning_planes\n",
    "        \n",
    "        self.res_conv_a = nn.Sequential(\n",
    "                        BasicBlock(1, planes, stride=1, downsample=None),\n",
    "                        BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                        BasicBlock(planes, planes, stride=1, downsample=None))\n",
    "\n",
    "        self.res_conv_x = nn.Sequential(\n",
    "                        BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                        BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                        BasicBlock(planes, planes, stride=1, downsample=None))\n",
    "        \n",
    "        self.bm = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.sample_down = {}\n",
    "        for key in self.keys:\n",
    "            self.sample_down[key] = nn.Linear(self.sizes[key], config.h_size)\n",
    "        \n",
    "    def forward(self, h, m):\n",
    "        keys = self.keys\n",
    "        dim_end = self.dim_words + 1\n",
    "\n",
    "        # try to sample down\n",
    "        m_high = [self.sample_down[key](m[key]).unsqueeze(dim_end) for key in keys]\n",
    "        m_high = torch.cat(tuple(m_high), dim=dim_end)\n",
    "        m_high = torch.sum(m_high, dim=dim_end) # sum retrieved memory along types: since types are supposed to be softmaxed, this makes sense\n",
    "\n",
    "        # reasoning step\n",
    "        a = torch.mul(h, m_high).unsqueeze(1) # add channel dimension\n",
    "        a = self.res_conv_a(a) \n",
    "        a = F.softmax(a, dim=self.dim_words)\n",
    "        x = torch.mul(m_high.unsqueeze(1), a)\n",
    "        x = self.res_conv_x(x) # x: batch_size, channel_size, embed_size, h_size\n",
    "        \n",
    "        x = self.bm(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAttend(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(QuestionAttend, self).__init__()\n",
    "        \n",
    "        self.dim_words = config.dim_words\n",
    "        planes = 16\n",
    "\n",
    "        self.res_conv_x = nn.Sequential(\n",
    "                                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                                nn.Conv2d(planes, 1, 3, stride=1, padding=1),\n",
    "                                nn.Linear(config.h_size, config.q_size))\n",
    "        \n",
    "    def forward(self, qa, x):\n",
    "\n",
    "        # downsample & reason\n",
    "        x_qa = self.res_conv_x(x).squeeze()\n",
    "        # attend\n",
    "        a = F.softmax(x_qa, dim=self.dim_words)\n",
    "        qa = torch.mul(qa, a)\n",
    "\n",
    "        return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSampleH(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(DownSampleH, self).__init__()\n",
    "        \n",
    "        pool_kernel = 3\n",
    "        pool_stride = 2\n",
    "        pool_num = 2\n",
    "        pool = [ nn.MaxPool1d(pool_kernel, stride=pool_stride) for i in range(pool_num) ]\n",
    "        \n",
    "        def pool_dim_func(k, size):\n",
    "            if k < 2:\n",
    "                return (size - (pool_kernel - 1) - 1) // pool_stride + 1\n",
    "            return (pool_dim_func(k-1, size) - (pool_kernel - 1) - 1) // pool_stride + 1\n",
    "        \n",
    "        \n",
    "        class Flatten(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(Flatten, self).__init__()\n",
    "\n",
    "            def forward(self, x):\n",
    "                s = x.size()\n",
    "                return x.view(s[0],-1)\n",
    "            \n",
    "        linear_feature = pool_dim_func(pool_num, config.h_size)* config.embed_size* config.bi\n",
    "        linear = [ Flatten(), nn.Linear(linear_feature, 1) ]\n",
    "        \n",
    "        self.downsample = nn.Sequential(*(pool+linear))\n",
    "    \n",
    "    def forward(self, h):\n",
    "        return self.downsample(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "class ForgetGate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ForgetGate, self).__init__()\n",
    "        \n",
    "        planes = 16\n",
    "        \n",
    "        self.res_conv_h = nn.Sequential(\n",
    "                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                nn.Conv2d(planes, 1, 3, stride=1, padding=1))\n",
    "\n",
    "        self.forget = Variable(torch.ones(1))\n",
    "        self.batch_size = config.batch_size\n",
    "        self.dim_words = config.dim_words\n",
    "        \n",
    "        self.downsample = DownSampleH(config)\n",
    "    \n",
    "    def forward(self, h, x):\n",
    "        h_new_input = self.res_conv_h(x).squeeze()\n",
    "        importance = self.downsample(h_new_input)\n",
    "        \n",
    "        forget = F.sigmoid(torch.mul(self.forget, importance)).unsqueeze(self.dim_words)\n",
    "        h_new = h*(1 - forget) + F.softmax(h_new_input, dim=self.dim_words)*forget # forget var should be learnable!\n",
    "        \n",
    "        return h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Confidence(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Confidence, self).__init__()\n",
    "        \n",
    "        self.downsample = DownSampleH(config)\n",
    "        \n",
    "    def forward(self, h):\n",
    "        \n",
    "        conf = self.downsample(h)\n",
    "        conf = F.sigmoid(conf)\n",
    "        \n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Output, self).__init__()\n",
    "        \n",
    "        planes = 16\n",
    "        \n",
    "        self.res_conv_o = nn.Sequential(\n",
    "                BasicBlock(1, planes, stride=1, downsample=None),\n",
    "                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                BasicBlock(planes, planes, stride=1, downsample=None),\n",
    "                nn.Conv2d(planes, 1, 3, stride=1, padding=1))\n",
    "        \n",
    "    def forward(self, h):\n",
    "        h = h.unsqueeze(1)\n",
    "        o = self.res_conv_o(h)\n",
    "        o = o.squeeze()\n",
    "        \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.dim_words = config.dim_words\n",
    "        self.ans_k = config.ans_k\n",
    "        \n",
    "        planes = 16\n",
    "        \n",
    "        self.sampledown = nn.Sequential(\n",
    "                            nn.Linear(config.a_size*config.h_size, config.hidden_size),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(config.hidden_size, config.a_size),\n",
    "                            nn.ReLU()\n",
    "                        )\n",
    "        \n",
    "        def self_attention(k, X):\n",
    "            # self attention\n",
    "            Y = torch.mul(X.unsqueeze(self.dim_words + 1), X.unsqueeze(self.dim_words + 2))\n",
    "            Y = torch.sum(Y, self.dim_words + 2).squeeze()\n",
    "            if k < 2:\n",
    "                return torch.mul(X, F.softmax(Y))\n",
    "            return torch.mul(self_attention(k - 1, X), F.softmax(Y))\n",
    "        \n",
    "        self.sa = self_attention\n",
    "        \n",
    "    def forward(self, o, A):\n",
    "        # naive probability\n",
    "        \n",
    "        o = o.squeeze()\n",
    "        A = A\n",
    "        x = torch.matmul(o.unsqueeze(3).unsqueeze(2), A.unsqueeze(3))\n",
    "        s = x.size()\n",
    "        x = x.view(s[0],s[1],-1,s[4])\n",
    "        x = self.sampledown(x.permute(0,1,3,2))\n",
    "        a = F.softmax(x.permute(0,1,3,2), dim=self.dim_words)\n",
    "        oa = torch.mul(A, a)\n",
    "        oa = oa.view(oa.size()[0], -1, oa.size()[3])\n",
    "        oa = torch.sum(oa, 1)\n",
    "        p = F.softmax(oa, dim=1)\n",
    "        \n",
    "        # answer patchwise probability       \n",
    "        A = torch.mul(A, p.unsqueeze(1).unsqueeze(1))\n",
    "        A = self.sa(self.ans_k, A)\n",
    "        \n",
    "        A = torch.sum(A, 1).squeeze()\n",
    "        A = torch.sum(A, 1).squeeze()\n",
    "        return A       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('argmax:', \n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 0\n",
      " 2\n",
      " 2\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 9 (GPU 0)]\n",
      ")\n",
      "('co:', torch.Size([5, 9, 226, 200]))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Performing basic indexing on a tensor and encountered an error indexing dim 0 with an object of type Variable. The only supported types are integers, slices, numpy scalars, or if indexing with a torch.cuda.LongTensor or torch.cuda.ByteTensor only a single Tensor may be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-02f0a8b09e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModuleNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/jiwan/tqa/baseline/mc/models/moduleNet/moduleNet.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, CO, Q, A)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# encoding layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/jiwan/tqa/baseline/mc/models/moduleNet/encoder.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, CO, Q, A)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'argmax:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'co:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# reduce based on top 1 indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size, embed_size, words_topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/jiwan/p2/local/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mIndexSelect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# else fall through and raise an error in Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/jiwan/p2/local/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, index)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_shared_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Performing basic indexing on a tensor and encountered an error indexing dim 0 with an object of type Variable. The only supported types are integers, slices, numpy scalars, or if indexing with a torch.cuda.LongTensor or torch.cuda.ByteTensor only a single Tensor may be passed."
     ]
    }
   ],
   "source": [
    "from utils.ReCuda import ReCuda\n",
    "\n",
    "config.reasoning_planes = 16\n",
    "config.k = 4\n",
    "config.conf = 0.7\n",
    "config.h_size = 128\n",
    "config.hyper = False\n",
    "config.hidden_size = 300\n",
    "config.dim_words = 2\n",
    "config.ans_k = 7\n",
    "config.bi = 2 if config.bi_gru else 1\n",
    "config.cuda = True\n",
    "\n",
    "# fix_length\n",
    "config.batch_size = 9\n",
    "config.q_size = 17\n",
    "config.a_size = 4\n",
    "config.c_size = 226\n",
    "config.keys = ['A', 'c']\n",
    "config.sizes = {'A': config.a_size, 'c': config.c_size}\n",
    "\n",
    "config.recuda = ReCuda(config)\n",
    "\n",
    "answers_size = len(data1.answers)\n",
    "answers = torch.stack(data1.answers, dim=2)\n",
    "topics = torch.stack(data1.topic, dim=2)\n",
    "\n",
    "CO = topics\n",
    "Q = data1.question\n",
    "A = answers\n",
    "\n",
    "net = ModuleNet(config, vocab).cuda()\n",
    "\n",
    "p = net.forward(CO, Q, A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ReCuda import ReCuda\n",
    "\n",
    "config.reasoning_planes = 16\n",
    "config.k = 4\n",
    "config.conf = 0.7\n",
    "config.h_size = 128\n",
    "config.hyper = False\n",
    "config.hidden_size = 300\n",
    "config.dim_words = 2\n",
    "config.ans_k = 7\n",
    "config.bi = 2 if config.bi_gru else 1\n",
    "config.cuda = True\n",
    "\n",
    "# fix_length\n",
    "config.batch_size = 9\n",
    "config.q_size = 17\n",
    "config.a_size = 4\n",
    "config.c_size = 226\n",
    "config.keys = ['A', 'c']\n",
    "config.sizes = {'A': config.a_size, 'c': config.c_size}\n",
    "\n",
    "config.recuda = ReCuda(config)\n",
    "\n",
    "answers_size = len(data1.answers)\n",
    "answers = torch.stack(data1.answers, dim=2)\n",
    "topics = torch.stack(data1.topic, dim=2)\n",
    "\n",
    "CO = topics.cpu()\n",
    "Q = data1.question.cpu()\n",
    "A = answers.cpu()\n",
    "\n",
    "net = ModuleNet(config, vocab)\n",
    "net = net.cuda()\n",
    "\n",
    "embed_size = config.embed_size\n",
    "\n",
    "embed = nn.Embedding(len(vocab), config.emb_dim)\n",
    "embed.weight.data.copy_(vocab.vectors)\n",
    "\n",
    "bi = 2 if config.bi_gru else 1\n",
    "\n",
    "embed_context = nn.GRU(config.emb_dim, embed_size, bidirectional=config.bi_gru)\n",
    "embed_question = nn.GRU(config.emb_dim, embed_size, bidirectional=config.bi_gru)\n",
    "embed_answer = nn.GRU(config.emb_dim, embed_size, bidirectional=config.bi_gru)\n",
    "normalize_row = nn.Softmax(dim=2)\n",
    "\n",
    "context_shape = list(CO.data.size())\n",
    "batch_size = context_shape[2]\n",
    "context_shape.append((config.embed_size* config.bi))\n",
    "CO = CO.view(-1, CO.size()[2])\n",
    "\n",
    "answer_shape = list(A.data.size())\n",
    "answer_shape.append((config.embed_size* config.bi))\n",
    "A = A.view(-1, A.size()[2])\n",
    "\n",
    "CO = embed(CO)\n",
    "Q = embed(Q)\n",
    "A = embed(A)\n",
    "\n",
    "CO, hc = embed_context(CO) # P x embed_size\n",
    "CO = CO.view(*context_shape)\n",
    "Q, hq = embed_question(Q) # Q X embed_size\n",
    "A, ha = embed_answer(A)\n",
    "A = A.view(*answer_shape) # A X embed_size\n",
    "\n",
    "CO = CO.permute(1, 2, 0, 3) # topic_num, batch_size, words_topic, embed_size\n",
    "Q = Q.permute(1, 2, 0) # batch_size, embed_size, words_question\n",
    "A = A.permute(2, 3, 0, 1) # batch_size, embed_size, words_answer, answer_num\n",
    "\n",
    "C = CO # store data\n",
    "\n",
    "# <attention>\n",
    "S = torch.matmul(C, Q) # topic_num, batch_size, words_topic, words_question\n",
    "S = normalize_row(S) # attention practice based on QAnet (Google)\n",
    "Att = torch.matmul(S, Q.permute(0, 2, 1)) # Q: batch_size, words_question, embed_size\n",
    "# Att: topic_num, batch_size, words_topic, embed_size\n",
    "C = F.normalize(C, dim=2) # normalize along words_topic, removing bias in total num of words\n",
    "C = torch.mul(Att, C) # apply attention\n",
    "C = torch.sum(torch.sum(C, 3), 2) # reduce dimension\n",
    "# </attention>\n",
    "\n",
    "C = C.cuda()\n",
    "CO = CO.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 1\n",
      " 1\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 9 (GPU 0)]\n",
      "\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      "[torch.cuda.LongTensor of size 9 (GPU 0)]\n",
      "\n",
      "torch.Size([9, 200, 226])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "maxval, argmax = torch.max(C, 0) # pick top 1 topic\n",
    "\n",
    "print(argmax)\n",
    "print(type(CO.data))\n",
    "b = torch.arange(0, batch_size).type_as(argmax.data)\n",
    "print(b)\n",
    "c = CO[argmax, b, :] # reduce based on top 1 indices\n",
    "c = c.permute(0, 2, 1) # batch_size, embed_size, words_topic \n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.FloatTensor"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
